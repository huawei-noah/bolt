
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Kit Example Â· GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-back-to-top-button/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-page-toc-button/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-insert-logo/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="CHANGELOG.html" />
    
    
    <link rel="prev" href="REDUCE_GPU_PREPARE_TIME.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    

    
        
        <li class="divider"></li>
        
        
    
        <li class="chapter " data-level="2.1" data-path="ARCHITECTURE.html">
            
                <a href="ARCHITECTURE.html">
            
                    
                    Architechture
            
                </a>
            

            
        </li>
    

    
        
        <li class="divider"></li>
        
        
    
        <li class="chapter " data-level="3.1" data-path="OPERATORS.html">
            
                <a href="OPERATORS.html">
            
                    
                    Operators
            
                </a>
            

            
        </li>
    

    
        
        <li class="divider"></li>
        
        
    
        <li class="chapter " data-level="4.1" data-path="INSTALL.html">
            
                <a href="INSTALL.html">
            
                    
                    Install
            
                </a>
            

            
        </li>
    

    
        
        <li class="divider"></li>
        
        
    
        <li class="chapter " data-level="5.1" data-path="USER_HANDBOOK.html">
            
                <a href="USER_HANDBOOK.html#basic-usage">
            
                    
                    Basic Usage
            
                </a>
            

            
        </li>
    

    
        
        <li class="divider"></li>
        
        
    
        <li class="chapter " data-level="6.1" data-path="USER_HANDBOOK.html">
            
                <a href="USER_HANDBOOK.html#advanced-features">
            
                    
                    Advanced Features
            
                </a>
            

            
        </li>
    

    
        
        <li class="divider"></li>
        
        
    
        <li class="chapter " data-level="7.1" data-path="DEVELOPER.html">
            
                <a href="DEVELOPER.html">
            
                    
                    Developer Customization
            
                </a>
            

            
        </li>
    

    
        
        <li class="divider"></li>
        
        
    
        <li class="chapter " data-level="8.1" data-path="REDUCE_GPU_PREPARE_TIME.html">
            
                <a href="REDUCE_GPU_PREPARE_TIME.html">
            
                    
                    How to Reduce MALI-GPU Initial Time
            
                </a>
            

            
        </li>
    

    
        
        <li class="divider"></li>
        
        
    
        <li class="chapter active" data-level="9.1" data-path="KIT.html">
            
                <a href="KIT.html">
            
                    
                    Kit Example
            
                </a>
            

            
        </li>
    

    
        
        <li class="divider"></li>
        
        
    
        <li class="chapter " data-level="10.1" data-path="CHANGELOG.html">
            
                <a href="CHANGELOG.html">
            
                    
                    Changelog
            
                </a>
            

            
        </li>
    

    
        
        <li class="divider"></li>
        
        
    
        <li class="chapter " data-level="11.1" data-path="FAQ.html">
            
                <a href="FAQ.html">
            
                    
                    FAQ
            
                </a>
            

            
        </li>
    

    
        
        <li class="divider"></li>
        
        
    
        <li class="chapter " data-level="12.1" data-path="FEEDBACK.html">
            
                <a href="FEEDBACK.html">
            
                    
                    Feedback
            
                </a>
            

            
        </li>
    

    
        
        <li class="divider"></li>
        
        
    
        <li class="chapter " data-level="13.1" data-path="IOS_USAGE.html">
            
                <a href="IOS_USAGE.html">
            
                    
                    Appendix
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >Kit Example</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="contents">Contents</h1>
<hr>
<p>&#xA0;&#xA0;&#xA0;&#xA0;<a href="#overview">Overview</a><br>&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;<a href="#ios-overview">iOS Overview</a><br>&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;<a href="#android-overview">Android Overview</a><br>&#xA0;&#xA0;&#xA0;&#xA0;<a href="#examples">Examples</a><br>&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;<a href="#image-classification">Image Classification</a>  </p>
<h1 id="overview">Overview</h1>
<hr>
<p>Kit is an experimental feature based on <a href="DEVELOPER.html">Flow</a>, which aims to simplify the integration of bolt into applications.
At this stage we are still rapidly exploring different designs. In the long run we want to provide symmetrical APIs for different platforms including iOS, Android, etc.
In the <a href="../kit">kit</a> directory, you can find the available demo project. In order to use the demo, bolt should be compiled first and some headers and libraries need to be installed into the project, which is also taken care of in <a href="../install.sh">install.sh</a>.</p>
<ul>
<li><h3 id="ios-overview">iOS Overview</h3>
<p>iOS demo is using the Objective-C Language and the C++ API of Flow. Mainbody of the codes is in <a href="../kit/iOS/ImageClassification/ImageClassification/ViewController.mm">ViewController.mm</a>. There are some notes regarding iOS kits:</p>
<ul>
<li>Compilation flags. The C++ API of Flow requires quite a few headers, and some compilation flags need to be set. For convenience, you can include <a href="../kit/iOS/image_classification/ImageClassificationDemo/libbolt/headers/kit_flags.h">kit_flags.h</a> before including flow.h.</li>
<li>Model path in flow prototxt. Flow reads the model paths in prototxt in order to locate the models. On iOS, however, the exact storage path for model files is dynamically determined. ViewController.mm demonstrates how to update prototxt with the new model path.</li>
</ul>
</li>
<li><h3 id="android-overview">Android Overview</h3>
<p>Android demo is using the C++ API of Flow via simple JNI. Mainbody of the codes is in <a href="../kit/Android/ImageClassification/app/src/main/cpp/native-lib.cpp">native-lib.cpp</a> or <a href="../kit/Android/ImageClassification/app/src/main/java/com/example/imageclassificationapp/MainActivity.java">MainActivity.java</a>.</p>
<ul>
<li>Compilation flags. Similar to iOS, some compilation flags are also set in <a href="../kit/Android/ImageClassification/app/src/main/cpp/libbolt/headers/kit_flags.h">kit_flags.h</a>.</li>
<li>GPU usage. The current project demonstrates CPU inference. We are still in the middle of refactoring the memory API, and when it completes the GPU usage will be symmetrical to CPU. To prevent careless mistakes, the project will only be set up when GPU compilation is off.</li>
</ul>
</li>
</ul>
<h1 id="examples">Examples</h1>
<hr>
<ul>
<li><h3 id="image-classification">Image Classification</h3>
<div align="center"><img src="images/ImageClassification.PNG" width="30%" height="30%"></div>

<p>The demo takes video input from camera, and uses <a href="https://github.com/huawei-noah/ghostnet" target="_blank">GhostNet</a> model trained on ImageNet. Given the same FLOPs, GhostNet shows a clear advantage over other lightweight CNNs. The models that we provide are trained with width as 1.0 on TensorFlow, which reaches a TOP1 accuracy of 74%.</p>
<p>You can easily switch to other models trained on other datasets, following the steps below. As a tutorial, we will show how to change the model to the FP16 GhostNet that is also included in the project (kit/models). Tested with single thread on our iPhone SE, switching to FP16 GhostNet allows the processing of each 224x224 image frame in under 9 ms as shown in the figure above. You can try other models if your device is older than iPhone X and thus not in ARMv8.2 architecture.</p>
<ol>
<li><p>In <a href="../kit/iOS/ImageClassification/ImageClassification/libbolt/image_classification.prototxt">image_classification.prototxt</a>, you can see that the Inference node includes a path to ghostnet_f32.bolt. Actually, it is not necessary to change this path to ghostnet_f16.bolt, because this path will be dynamically overwritten as explained above. We will show how to switch to FP16 in Step 1.</p>
<p>   <strong>In the following steps, if the file name is not specified, please check ViewController.mm.</strong></p>
</li>
<li><p>Switch to FP16 model. Change code to:</p>
<pre><code> NSString *boltPath=[[NSBundle mainBundle]pathForResource:@&quot;ghostnet_f16&quot; ofType:@&quot;bolt&quot;];
</code></pre><p> Please also change the variable inferencePrecision to DT_F16.</p>
</li>
<li><p>Adjust the pixelProcess function, which is registered as the preprocessing function for the Inference node. For FP16 inference, actual input to the model should be in FP16:</p>
<pre><code> F16 *oneArr = (F16 *)((CpuMemory *)outputs[&quot;input:0&quot;]-&gt;get_memory())-&gt;get_ptr();
</code></pre><p> If you are using your own model, change &quot;input:0&quot; to the name of your model input tensor.</p>
<p> The provided Ghostnet requires input pixels organized as BGRBGRBGR... Adjust accordingly if your other model is trained with different preprocessing (i.e. normalizing each channel).</p>
</li>
<li><p>Adjust the postProcess function, which is registered as the postprocessing function for the Inference node. For FP16 inference, the output score is also in FP16:</p>
<pre><code> F16 *score1000 =(F16 *)((CpuMemory *)inputs[boltModelOutputName]-&gt;get_memory())-&gt;get_ptr();
</code></pre><p> If necessary, change boltModelOutputName to the name of your model output tensor. If your model is not trained on ImageNet, there may not be 1000 scores. You may also change the topK variable.</p>
</li>
<li><p>If necessary, replace imagenet_classes.txt. Add codes to handle the class index numbers that Flow outputs.</p>
<p>   <em>NOTE: Android can also follow the above steps and make similar modifications.</em></p>
</li>
</ol>
</li>
<li><h3 id="camera-enlarge">Camera Enlarge</h3>
<div align="center"><img src="images/CameraEnlarge.PNG" width="30%" height="30%"></div>

<p>The demo takes video input from camera, 32 pixels x 32 pixels, and uses <a href="https://github.com/huawei-noah/vega/blob/master/docs/en/algorithms/esr_ea.md" target="_blank">ESR_EA</a> model to enlarge input image to 64 pixels x 64 pixels.</p>
<p>You can easily switch to other models trained on other datasets, following the steps below. As a tutorial, we will show how to change the model to the FP16 ESR_EA that is also included in the project (kit/models).</p>
<ol>
<li><p>Similar with Image Classification</p>
</li>
<li><p>Similar with Image Classification</p>
</li>
<li><p>Adjust the pixelProcess function, which is registered as the preprocessing function for the Inference node. For FP16 inference, actual input to the model should be in FP16:</p>
<pre><code>F16 *oneArr = (F16 *)((CpuMemory *)outputs[&quot;input.1&quot;]-&gt;get_memory())-&gt;get_ptr();
</code></pre><p>If you are using your own model, change &quot;input.1&quot; to the name of your model input tensor.
The provided Ghostnet requires input pixels organized as RGBRGBRGB... Adjust accordingly if your other model is trained with different preprocessing (i.e. normalizing each channel).</p>
</li>
<li><p>Adjust the postProcess function, which is registered as the postprocessing function for the Inference node. For FP16 inference, the output pixel data is also in FP16,Process the data, assign values &#x200B;&#x200B;less than 1 to 0, assign values &#x200B;&#x200B;greater than 255 to 255, and then split and reorganize the data:</p>
<pre><code>F16 *rgbData =(F16 *)((CpuMemory *)inputs[boltModelOutputName]-&gt;get_memory())-&gt;get_ptr();
F16 *rArr=(F16*)malloc(sizeof(F32*)*imgHeight*2*imgWidth*2);
F16 *gArr=(F16*)malloc(sizeof(F32*)*imgHeight*2*imgWidth*2);
F16 *bArr=(F16*)malloc(sizeof(F32*)*imgHeight*2*imgWidth*2);
for (int i = 0; i &lt;(imgHeight*2)*(imgWidth*2)*3; i++) {
    if(rgbData[i]&lt;=1) {
        int a=0;
        rgbData[i]=a;
    }else if (rgbData[i]&gt;255) {
        int b=255;
        rgbData[i]=b;
    }

    if (i&lt;(imgHeight*2)*(imgWidth*2)) {
        gArr[i]=rgbData[i];
    } else if(i&lt;(imgHeight*2)*(imgWidth*2)*2) {
        bArr[i-(imgHeight*2)*(imgWidth*2)]=rgbData[i];
    } else {
        rArr[i-2*(imgHeight*2)*(imgWidth*2)]=rgbData[i];
    }
}
</code></pre></li>
</ol>
</li>
<li><h3 id="semantics">Semantics</h3>
<div align="center"><img src="images/Semantics.PNG" width="30%" height="30%"></div>

<p>The demo tokenize input words, and use <a href="https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/TinyBERT" target="_blank">tinybert</a> model to do senmantic analysis.</p>
<p>You can easily switch to other models trained on other datasets, following the steps below. As a tutorial, we will show how to change the model to the FP32 Tinybert that is also included in the project.</p>
<ol>
<li><p>Copy the path of the model file to the cache path so that the Jni method in the dynamic library can be called.</p>
<pre><code>copyAssetResource2File(MODEL, modelPath);
</code></pre></li>
<li><p>set the input and output names and other input parameters according to your model to initialize BoltModel.</p>
<pre><code>int inputNum = 3;
int outputNum = 1;
String[] inputName = {&quot;input_ids&quot;,&quot;position_ids&quot;,&quot;token_type_ids&quot;};
String[] outputName = {&quot;logit&quot;};
int[] inputN = {1,1,1};
int[] inputCMax = {64,64,64};
int[] inputH = {1,1,1};
int[] inputW = {1,1,1};
DataType[] intputDataType = {DataType.INT32,DataType.INT32,DataType.INT32};
DataFormat[] intputDataFormat = {DataFormat.NORMAL,DataFormat.NORMAL,DataFormat.NORMAL};
BoltModel boltModel = new BoltModel(modelPath, AffinityType.CPU_HIGH_PERFORMANCE, inputNum, inputName, inputN,
        inputCMax, inputH, inputW, intputDataType, intputDataFormat, outputNum, outputName);
</code></pre></li>
<li><p>Call the run method of the BoltModel class to obtain the output result. Tokenizers are the processed input data, and inputCActual is the actual length of the input data. Call getResultData of BoltResult class to get the analysis result, get the result array, two float data.</p>
<pre><code>float[][] tokenizers = appTokenizer.runTokenizer(sentence);
int[] inputCActual = {tokenizers[0].length, tokenizers[1].length, tokenizers[2].length};

BoltResult boltResult = boltModel.run(inputNum, inputName, inputN, inputCActual, inputH,
        inputW, intputDataType, intputDataFormat, tokenizers);
float[][] result = boltResult.getResultData();
</code></pre></li>
<li><p>Obtain the analysis result by comparing the size of the two probabilities in the result array</p>
<pre><code>if (result[0][0]&gt;result[0][1]) {
   tvIntent.setText(&quot;negative&quot;);
} else {
  tvIntent.setText(&quot;positive&quot;);
}
</code></pre></li>
</ol>
</li>
<li><h3 id="chinesespeechrecognition">ChineseSpeechRecognition</h3>
<div align="center"><img src="images/ChineseSpeechRecognition.PNG" width="30%" height="30%"></div>

<p>The demo recognizes the input Chinese speech, and uses the <a href="https://github.com/huawei-noah/xxx" target="_blank">ASR</a> model to convert Chinese text.</p>
<p>You can easily switch to other models trained on other datasets, following the steps below. As a tutorial, we will show how to change the model to the FP32 ASR that is also included in the project.</p>
<ol>
<li><p>Call the copyAssetAndWrite method to copy the path, and then change the path of the bin file and bolt model in the prototxt file to the copied path</p>
</li>
<li><p>Import flow_asr.h in native-lib, flow_asr defines the pre- and post-processing methods and the initialization of flow and the acquisition of results,add init method and get result method in native-lib.cpp</p>
<pre><code>extern &quot;C&quot;
JNIEXPORT void JNICALL
Java_com_huawei_noah_MainActivity_initFlow(JNIEnv *env, jobject thiz, jstring encoder_path,
                                           jstring predic_path, jstring joint_path,
                                           jstring pinyin_path,jstring label_path) {
    encoderGraphPath = env-&gt;GetStringUTFChars(encoder_path, nullptr);
    predictionGraphPath = env-&gt;GetStringUTFChars(predic_path, nullptr);
    jointGraphPath = env-&gt;GetStringUTFChars(joint_path, nullptr);
    pinyin2hanziGraphPath = env-&gt;GetStringUTFChars(pinyin_path, nullptr);
    labelFilePath = env-&gt;GetStringUTFChars(label_path, nullptr);

    initASRFlow();
}

extern &quot;C&quot;
JNIEXPORT jstring JNICALL
Java_com_huawei_noah_MainActivity_runFlow(JNIEnv *env, jobject thiz, jstring wav_file_path) {
    std::string wavFilePath = env-&gt;GetStringUTFChars(wav_file_path, nullptr);
    std::string hanzi = runASRFlow(wavFilePath);
    return env-&gt;NewStringUTF(hanzi.c_str());
}
</code></pre></li>
<li><p>Call Jni method  initFlow</p>
<pre><code>initFlow(getCacheDir()+&quot;/encoder_flow.prototxt&quot;,getCacheDir()+&quot;/prediction_flow.prototxt&quot;,
               getCacheDir()+&quot;/joint_flow.prototxt&quot;,getCacheDir()+&quot;/pinyin2hanzi_flow.prototxt&quot;,getCacheDir()+&quot;/asr_labels.txt&quot;);
</code></pre></li>
<li><p>Call Jni method  runFlow Incoming audio files in wav format get result</p>
<pre><code>runFlow(wavFileName)
</code></pre></li>
</ol>
</li>
<li><h3 id="facedetection">FaceDetection</h3>
<div align="center"><img src="images/FaceDetection.PNG" width="30%" height="30%"></div>

<p>The demo detects the input picture, and outputs A photo framed a human face.</p>
<ol>
<li><p>bolt path get Similar with Semantics</p>
</li>
<li><p>Call the getDetectionImgPath method Bitmap and model path to go directly to the detection result picture path</p>
<pre><code>resultImgPath=boltResult.getDetectionImgPath(bitmap,boltPath);
</code></pre></li>
<li><p>The parameters in the prior_boxes_generator method in the jni method initBolt are fixed input parameters of the model and cannot be changed</p>
<pre><code>prior_boxes_generator(320,240,0.7,0.3);
</code></pre></li>
</ol>
</li>
</ul>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="REDUCE_GPU_PREPARE_TIME.html" class="navigation navigation-prev " aria-label="Previous page: How to Reduce MALI-GPU Initial Time">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="CHANGELOG.html" class="navigation navigation-next " aria-label="Next page: Changelog">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Kit Example","level":"9.1","depth":1,"next":{"title":"Changelog","level":"10.1","depth":1,"path":"docs/CHANGELOG.md","ref":"docs/CHANGELOG.md","articles":[]},"previous":{"title":"How to Reduce MALI-GPU Initial Time","level":"8.1","depth":1,"path":"docs/REDUCE_GPU_PREPARE_TIME.md","ref":"docs/REDUCE_GPU_PREPARE_TIME.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":["github","back-to-top-button","page-toc-button","insert-logo","livereload"],"pluginsConfig":{"github":{"url":"https://github.com/huawei-noah/bolt"},"livereload":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"fontsettings":{"theme":"white","family":"sans","size":2},"highlight":{},"page-toc-button":{"maxTocDepth":1,"minTocSize":2},"back-to-top-button":{},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false},"insert-logo":{"style":"background:none;max-height:100px","url":"../docs/images/LOGO.PNG"}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"docs/KIT.md","mtime":"2021-09-30T01:49:08.000Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2021-09-30T18:21:25.119Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-github/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-back-to-top-button/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-page-toc-button/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-insert-logo/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-livereload/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

